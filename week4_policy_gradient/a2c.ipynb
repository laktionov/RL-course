{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-pAd9Dl-l1-g"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week08_pomdp/atari_util.py\n",
        "    !wget https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week08_pomdp/env_pool.py\n",
        "\n",
        "    !pip install -q gymnasium[atari,accept-rom-license]\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "    !touch .setup_complete\n",
        "# If you are running on a server, launch xvfb to record game videos\n",
        "# Please make sure you have xvfb installed\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1uoqJM38aOn",
        "outputId": "3e2c98fc-bcc1-4bda-a226-abe0d688cd0e"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "maW-b-Qql1-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.core import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRcd47Kzl1-h"
      },
      "source": [
        "### Kung-Fu, recurrent style\n",
        "\n",
        "In this notebook we'll once again train RL agent for for Atari [KungFuMaster](https://gymnasium.farama.org/environments/atari/kung_fu_master/), this time using recurrent neural networks.\n",
        "\n",
        "![img](https://upload.wikimedia.org/wikipedia/en/6/66/Kung_fu_master_mame.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLtn2QwEl1-h",
        "outputId": "e173a31e-cd80-4d54-8821-eb13980c676d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation shape: (1, 42, 42)\n",
            "Num actions: 14\n",
            "Action names: ['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from atari_util import PreprocessAtari\n",
        "\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"KungFuMasterDeterministic-v0\", render_mode=\"rgb_array\")\n",
        "    env = PreprocessAtari(env, height=42, width=42,\n",
        "                          crop=lambda img: img[60:-30, 15:],\n",
        "                          color=False, n_frames=1)\n",
        "    return env\n",
        "\n",
        "\n",
        "env = make_env()\n",
        "\n",
        "obs_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"Observation shape:\", obs_shape)\n",
        "print(\"Num actions:\", n_actions)\n",
        "print(\"Action names:\", env.env.env.get_action_meanings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "GFtTWeWwl1-i",
        "outputId": "66c387e2-b3e5-4bf7-82e5-3ff656586900"
      },
      "outputs": [],
      "source": [
        "s = env.reset()\n",
        "for _ in range(100):\n",
        "    s, _, _, _, _ = env.step(env.action_space.sample())\n",
        "\n",
        "plt.title('Game image')\n",
        "plt.imshow(env.render())\n",
        "plt.show()\n",
        "\n",
        "plt.title('Agent observation')\n",
        "plt.imshow(s.reshape([42, 42]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G0WNE0Sl1-i"
      },
      "source": [
        "### POMDP setting\n",
        "\n",
        "The Atari game we're working with is actually a POMDP: your agent needs to know timing at which enemies spawn and move, but cannot do so unless it has some memory. \n",
        "\n",
        "Let's design another agent that has a recurrent neural net memory to solve this. Here's a sketch.\n",
        "\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/blob/master/week08_pomdp/img1.jpg?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pobJ2VHYl1-i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleRecurrentAgent(nn.Module):\n",
        "    def __init__(self, obs_shape, n_actions, reuse=False):\n",
        "        \"\"\"A simple actor-critic agent\"\"\"\n",
        "        super().__init__()\n",
        "        <YOUR CODE>      \n",
        "\n",
        "    def forward(self, prev_state, obs_t):\n",
        "        \"\"\"\n",
        "        Takes agent's previous hidden state and a new observation,\n",
        "        returns a new hidden state and whatever the agent needs to learn\n",
        "        \"\"\"\n",
        "\n",
        "        # Apply the whole neural net for one step here.\n",
        "        # See docs on self.rnn(...).\n",
        "        # The recurrent cell should take the last feedforward dense layer as input.\n",
        "        <YOUR CODE>      \n",
        "\n",
        "        return new_state, (logits, state_value)\n",
        "\n",
        "    def get_initial_state(self, batch_size):\n",
        "        \"\"\"Return a list of agent memory states at game start. Each state is a np array of shape [batch_size, ...]\"\"\"\n",
        "        return torch.zeros((batch_size, 128)), torch.zeros((batch_size, 128))\n",
        "\n",
        "    def sample_actions(self, agent_outputs):\n",
        "        \"\"\"pick actions given numeric agent outputs (np arrays)\"\"\"\n",
        "        logits, state_values = agent_outputs\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        return torch.multinomial(probs, 1)[:, 0].data.numpy()\n",
        "\n",
        "    def step(self, prev_state, obs_t):\n",
        "        \"\"\" like forward, but obs_t is a numpy array \"\"\"\n",
        "        obs_t = torch.tensor(np.asarray(obs_t), dtype=torch.float32)\n",
        "        (h, c), (l, s) = self.forward(prev_state, obs_t)\n",
        "        return (h.detach(), c.detach()), (l.detach(), s.detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bIWPiTUVl1-j"
      },
      "outputs": [],
      "source": [
        "n_parallel_games = 5\n",
        "gamma = 0.99\n",
        "\n",
        "agent = SimpleRecurrentAgent(obs_shape, n_actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcRP2zj5l1-j",
        "outputId": "06c4e95f-2b57-4d1f-ebdf-9ec7a8621423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "action logits:\n",
            " tensor([[ 0.0488, -0.0060,  0.0492, -0.0668, -0.0233,  0.0097,  0.0430, -0.0625,\n",
            "         -0.0087,  0.0485, -0.0756,  0.0298,  0.0122, -0.0861]])\n",
            "state values:\n",
            " tensor([[-0.0480]])\n"
          ]
        }
      ],
      "source": [
        "state = [env.reset()[0]]\n",
        "_, (logits, value) = agent.step(agent.get_initial_state(1), state)\n",
        "print(\"action logits:\\n\", logits)\n",
        "print(\"state values:\\n\", value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40VbE0Ghl1-j"
      },
      "source": [
        "### Let's play!\n",
        "Let's build a function that measures agent's average reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OJ08_WPSl1-j"
      },
      "outputs": [],
      "source": [
        "def evaluate(agent, env, n_games=1):\n",
        "    \"\"\"Plays an entire game start to end, returns session rewards.\"\"\"\n",
        "\n",
        "    game_rewards = []\n",
        "    for _ in range(n_games):\n",
        "        # initial observation and memory\n",
        "        observation = env.reset()[0]\n",
        "        prev_memories = agent.get_initial_state(1)\n",
        "\n",
        "        total_reward = 0\n",
        "        while True:\n",
        "            new_memories, readouts = agent.step(\n",
        "                prev_memories, observation[None, ...])\n",
        "            action = agent.sample_actions(readouts)\n",
        "\n",
        "            observation, reward, terminated, truncated, _ = env.step(action[0])\n",
        "\n",
        "            total_reward += reward\n",
        "            prev_memories = new_memories\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        game_rewards.append(total_reward)\n",
        "    return game_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_lgf7M-l1-j"
      },
      "outputs": [],
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with RecordVideo(make_env(), video_folder=\"videos\") as env_monitor:\n",
        "    rewards = evaluate(agent, env_monitor, n_games=3)\n",
        "\n",
        "print(rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3mLmBHil1-j"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHcHf6M2l1-k"
      },
      "source": [
        "### Training on parallel games\n",
        "\n",
        "We introduce a class called EnvPool - it's a tool that handles multiple environments for you. Here's how it works:\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/blob/master/week08_pomdp/img2.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-B4-V38l1-k",
        "outputId": "423322d8-2745-4efd-9914-b40bfe155525"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gymnasium/envs/registration.py:578: UserWarning: \u001b[33mWARN: The environment KungFuMasterDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "from env_pool import EnvPool\n",
        "pool = EnvPool(agent, make_env, n_parallel_games)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymPfmKA-l1-k"
      },
      "source": [
        "We gonna train our agent on a thing called __rollouts:__\n",
        "![img](https://github.com/yandexdataschool/Practical_RL/blob/master/week08_pomdp/img3.jpg?raw=1)\n",
        "\n",
        "A rollout is just a sequence of T observations, actions and rewards that agent took consequently.\n",
        "* First __s0__ is not necessarily initial state for the environment\n",
        "* Final state is not necessarily terminal\n",
        "* We sample several parallel rollouts for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "MP7Le6psl1-k"
      },
      "outputs": [],
      "source": [
        "# for each of n_parallel_games, take 10 steps\n",
        "rollout_obs, rollout_actions, rollout_rewards, rollout_mask = pool.interact(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHfcyB0Hl1-k",
        "outputId": "6ba4b693-a961-4d3d-9733-5ae6339e3535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions shape: (5, 10)\n",
            "Rewards shape: (5, 10)\n",
            "Mask shape: (5, 10)\n",
            "Observations shape:  (5, 10, 1, 42, 42)\n"
          ]
        }
      ],
      "source": [
        "print(\"Actions shape:\", rollout_actions.shape)\n",
        "print(\"Rewards shape:\", rollout_rewards.shape)\n",
        "print(\"Mask shape:\", rollout_mask.shape)\n",
        "print(\"Observations shape: \", rollout_obs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UQj-Dvzl1-k"
      },
      "source": [
        "# Actor-critic objective\n",
        "\n",
        "Here we define a loss function that uses rollout above to train advantage actor-critic agent.\n",
        "\n",
        "\n",
        "Our loss consists of three components:\n",
        "\n",
        "* __The policy \"loss\"__\n",
        " $$ \\hat J = {1 \\over T} \\cdot \\sum_t { \\log \\pi(a_t | s_t) } \\cdot A_{const}(s_t, a_t) $$\n",
        "  * This function has no meaning in and of itself, but it was built such that\n",
        "  * $ \\nabla \\hat J = {1 \\over N} \\cdot \\sum_t { \\nabla \\log \\pi(a_t | s_t) } \\cdot A(s,a) \\approx \\nabla E_{s, a \\sim \\pi} R(s,a) $\n",
        "  * Therefore if we __maximize__ $\\hat{J}$ with gradient ascent we will maximize expected reward\n",
        "  \n",
        "  \n",
        "* __The value \"loss\"__\n",
        "  $$ L_{td} = {1 \\over T} \\cdot \\sum_t { [r + \\gamma \\cdot V_{const}(s_{t+1}) - V(s_t)] ^ 2 }$$\n",
        "  * TD_loss from q-learning and alike\n",
        "  * If we minimize this loss, $V(s)$ will converge to $V_\\pi(s) = E_{a \\sim \\pi(a | s)} R(s,a) $\n",
        "\n",
        "\n",
        "* __Entropy Regularizer__\n",
        "  $$ H = - {1 \\over T} \\sum_t \\sum_a {\\pi(a|s_t) \\cdot \\log \\pi (a|s_t)}$$\n",
        "  * If we __maximize__ entropy we discourage agent from predicting zero probability to actions\n",
        "  prematurely (a.k.a. exploration)\n",
        "  \n",
        "  \n",
        "So we optimize a linear combination of $L_{td}- \\hat J -H$\n",
        "\n",
        "\n",
        "\n",
        "__One more thing:__ since we train on T-step rollouts, we can use N-step formula for advantage for free:\n",
        "  * At the last step, $A(s_t,a_t) = r(s_t, a_t) + \\gamma \\cdot V(s_{t+1}) - V(s_t) $\n",
        "  * One step earlier, $A(s_t,a_t) = r(s_t, a_t) + \\gamma \\cdot r(s_{t+1}, a_{t+1}) + \\gamma ^ 2 \\cdot V(s_{t+2}) - V(s_t) $\n",
        "  * Et cetera, et cetera. This way agent starts training much faster since it's estimate of A(s,a) depends less on his (imperfect) value function and more on actual rewards. There's also a [nice generalization](https://arxiv.org/abs/1506.02438) of this.\n",
        "\n",
        "\n",
        "__Note:__ it's also a good idea to scale rollout_len up to learn longer sequences. You may wish set it to >=20 or to start at 10 and then scale up as time passes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "0Wul2RWkl1-k"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "to_one_hot = F.one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "2AihqetAl1-k"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(agent.parameters(), lr=1e-5)\n",
        "\n",
        "def train_on_rollout(states, actions, rewards, is_not_done, \n",
        "                     prev_memory_states, gamma=0.99):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # shape: [batch_size, time, c, h, w]\n",
        "    states = torch.tensor(np.asarray(states), dtype=torch.float32)\n",
        "    actions = torch.tensor(np.array(actions), dtype=torch.int64)  # shape: [batch_size, time]\n",
        "    rewards = torch.tensor(np.array(rewards), dtype=torch.float32)  # shape: [batch_size, time]\n",
        "    is_not_done = torch.tensor(np.array(is_not_done), dtype=torch.float32)  # shape: [batch_size, time]\n",
        "    rollout_length = rewards.shape[1] - 1\n",
        "\n",
        "    # predict logits, probs and log-probs using an agent.\n",
        "    memory = [m.detach() for m in prev_memory_states]\n",
        "\n",
        "    logits = []  # append logit sequence here\n",
        "    state_values = []  # append state values here\n",
        "    for t in range(rewards.shape[1]):\n",
        "        obs_t = states[:, t]\n",
        "\n",
        "        # use agent to comute logits_t and state values_t.\n",
        "        # append them to logits and state_values array\n",
        "\n",
        "        memory, (logits_t, values_t) = <YOUR CODE>\n",
        "\n",
        "        logits.append(logits_t)\n",
        "        state_values.append(values_t)\n",
        "\n",
        "    logits = torch.stack(logits, dim=1)\n",
        "    state_values = torch.stack(state_values, dim=1)\n",
        "    probs = F.softmax(logits, dim=2)\n",
        "    logprobs = F.log_softmax(logits, dim=2)\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    actions_one_hot = F.one_hot(actions, dim=1).view(\n",
        "        actions.shape[0], actions.shape[1], n_actions)\n",
        "    logprobs_for_actions = torch.sum(logprobs * actions_one_hot, dim=-1)\n",
        "\n",
        "    # Now let's compute two loss components:\n",
        "    # 1) Policy gradient objective.\n",
        "    # Notes: Please don't forget to call .detach() on advantage term. Also please use mean, not sum.\n",
        "    # it's okay to use loops if you want\n",
        "    J_hat = 0  # policy objective as in the formula for J_hat\n",
        "\n",
        "    # 2) Temporal difference MSE for state values\n",
        "    # Notes: Please don't forget to call on V(s') term. Also please use mean, not sum.\n",
        "    # it's okay to use loops if you want\n",
        "    value_loss = 0\n",
        "\n",
        "    cumulative_returns = state_values[:, -1].detach()\n",
        "\n",
        "    for t in reversed(range(rollout_length)):\n",
        "        r_t = rewards[:, t]                                # current rewards\n",
        "        # current state values\n",
        "        V_t = state_values[:, t]\n",
        "        V_next = state_values[:, t + 1].detach()           # next state values\n",
        "        # log-probability of a_t in s_t\n",
        "        logpi_a_s_t = logprobs_for_actions[:, t]\n",
        "\n",
        "        # update G_t = r_t + gamma * G_{t+1} as we did in week6 reinforce\n",
        "        cumulative_returns = G_t = r_t + gamma * cumulative_returns\n",
        "\n",
        "        # Compute temporal difference error (MSE for V(s))\n",
        "        value_loss += <YOUR CODE>\n",
        "\n",
        "        # compute advantage A(s_t, a_t) using cumulative returns and V(s_t) as baseline\n",
        "        advantage = <YOUR CODE>\n",
        "        advantage = advantage.detach()\n",
        "\n",
        "        # compute policy pseudo-loss aka -J_hat.\n",
        "        J_hat += <YOUR CODE>\n",
        "\n",
        "    # regularize with entropy\n",
        "    entropy_reg = <YOUR CODE: compute entropy regularizer>\n",
        "\n",
        "    # add-up three loss components and average over time\n",
        "    loss = -J_hat / rollout_length +\\\n",
        "        value_loss / rollout_length +\\\n",
        "           -0.01 * entropy_reg\n",
        "\n",
        "    # Gradient descent step\n",
        "    <YOUR CODE>\n",
        "\n",
        "    return loss.data.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaHMJgRhl1-l",
        "outputId": "88c43082-274e-4e0d-dd43-ff9dc7255cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[200.0]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's test it\n",
        "memory = list(pool.prev_memory_states)\n",
        "rollout_obs, rollout_actions, rollout_rewards, rollout_mask = pool.interact(10)\n",
        "\n",
        "train_on_rollout(rollout_obs, rollout_actions,\n",
        "                 rollout_rewards, rollout_mask, memory)\n",
        "evaluate(agent, env, n_games=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbhKHD1hl1-l"
      },
      "source": [
        "# Train \n",
        "\n",
        "just run train step and see if agent learns any better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "3O01oj0Yl1-l"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange\n",
        "from pandas import DataFrame\n",
        "moving_average = lambda x, **kw: DataFrame(\n",
        "    {'x': np.asarray(x)}).x.ewm(**kw).mean().values\n",
        "\n",
        "rewards_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1LjSfKwYl1-l",
        "outputId": "a13d7271-7cdd-444a-f30b-16e9c743d315"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|â–‹         | 1017/15000 [07:22<1:22:14,  2.83it/s]"
          ]
        }
      ],
      "source": [
        "for i in trange(15000):\n",
        "\n",
        "    memory = list(pool.prev_memory_states)\n",
        "    rollout_obs, rollout_actions, rollout_rewards, rollout_mask = pool.interact(10)\n",
        "    train_on_rollout(rollout_obs, rollout_actions, rollout_rewards, rollout_mask, memory)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        rewards_history.append(np.mean(evaluate(agent, env, n_games=1)))\n",
        "        clear_output(True)\n",
        "        plt.plot(rewards_history, label='rewards')\n",
        "        plt.plot(moving_average(np.array(rewards_history),\n",
        "                                span=10), label='rewards ewma@10')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        if rewards_history[-1] >= 10000:\n",
        "            print(\"Your agent has just passed the minimum homework threshold\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hJqvpfFl1-l"
      },
      "source": [
        "Relax and grab some refreshments while your agent is locked in an infinite loop of violence and death.\n",
        "\n",
        "__How to interpret plots:__\n",
        "\n",
        "The session reward is the easy thing: it should in general go up over time, but it's okay if it fluctuates ~~like crazy~~. It's also OK if it reward doesn't increase substantially before some 10k initial steps. However, if reward reaches zero and doesn't seem to get up over 2-3 evaluations, there's something wrong happening.\n",
        "\n",
        "\n",
        "Since we use a policy-based method, we also keep track of __policy entropy__ - the same one you used as a regularizer. The only important thing about it is that your entropy shouldn't drop too low (`< 0.1`) before your agent gets the yellow belt. Or at least it can drop there, but _it shouldn't stay there for long_.\n",
        "\n",
        "If it does, the culprit is likely:\n",
        "* Some bug in entropy computation. Remember that it is $ - \\sum p(a_i) \\cdot log p(a_i) $\n",
        "* Your agent architecture converges too fast. Increase entropy coefficient in actor loss. \n",
        "* Gradient explosion - just [clip gradients](https://stackoverflow.com/a/56069467) and maybe use a smaller network\n",
        "* Us. Or PyTorch developers. Or aliens. Or lizardfolk. Contact us on forums before it's too late!\n",
        "\n",
        "If you're debugging, just run `logits, values = agent.step(batch_states)` and manually look into logits and values. This will reveal the problem 9 times out of 10: you'll likely see some NaNs or insanely large numbers or zeros. Try to catch the moment when this happens for the first time and investigate from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dGbxqvcl1-l"
      },
      "source": [
        "### \"Final\" evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_trlh5Akl1-l",
        "outputId": "60aeb56e-f660-467b-e170-37eba53d3230"
      },
      "outputs": [],
      "source": [
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "with RecordVideo(make_env(), video_folder=\"videos\") as env_monitor:\n",
        "    final_rewards = evaluate(agent, env_monitor, n_games=20)\n",
        "\n",
        "print(\"Final mean reward\", np.mean(final_rewards))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "LNJHTDFnl1-l",
        "outputId": "a1557dd5-98e9-4d6a-94a2-f36785fd4285"
      },
      "outputs": [],
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_paths = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "video_path = video_paths[-1]  # You can also try other indices\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # https://stackoverflow.com/a/57378660/1214547\n",
        "    with video_path.open('rb') as fp:\n",
        "        mp4 = fp.read()\n",
        "    data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "else:\n",
        "    data_url = str(video_path)\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(data_url))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
