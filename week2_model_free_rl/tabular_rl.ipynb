{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76HMQXahvkXf"
      },
      "source": [
        "# Seminar 2: Model Free Tabular RL\n",
        "\n",
        "Original notebook: https://github.com/yandexdataschool/Practical_RL/tree/master/week03_model_free\n",
        "\n",
        "This notebook will guide you through implementation of vanilla Q-learning and SARSA algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6TmBtStvkXh"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !pip install -q gymnasium\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDnIn5ebvkXh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfxN3ZZkcVaK"
      },
      "source": [
        "TLDR:\n",
        "\n",
        "* Q-learning: for each transition $(s, a, r, s')$ update:\n",
        "\n",
        "$$Q(s, a) \\leftarrow Q(s, a) + \\alpha [r + \\gamma \\max_{a'} Q(s', a') - Q(s, a)]$$\n",
        "\n",
        "* SARSA: for each transition $(s, a, r, s', a')$ update\n",
        "\n",
        "$$Q(s, a) \\leftarrow Q(s, a) + \\alpha [r + \\gamma Q(s', a') - Q(s, a)]$$\n",
        "\n",
        "* Expected SARSA: for each transition $(s, a, r, s')$ update\n",
        "\n",
        "$$Q(s, a) \\leftarrow Q(s, a) + \\alpha [r + \\gamma \\mathbb{E}_{a' \\sim \\mu(.| s)} Q(s', a') - Q(s, a)],$$\n",
        "\n",
        "where $\\mu(.|s)$ is a behaviour policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzJp0QlBd--J"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__5YvwmVvkXi"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly.\n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if not possible_actions:\n",
        "            return 0.0\n",
        "\n",
        "        <YOUR CODE>\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters_\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        q_value = <YOUR CODE>\n",
        "\n",
        "        self.set_qvalue(state, action, q_value)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values).\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if not possible_actions:\n",
        "            return None\n",
        "\n",
        "        best_action = <YOUR CODE>\n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.\n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list).\n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if not possible_actions:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        chosen_action = <YOUR CODE>\n",
        "\n",
        "        return chosen_action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geQxGO9lvkXj"
      },
      "source": [
        "### Try it on taxi\n",
        "\n",
        "Here we use the qlearning agent on taxi env from openai gym.\n",
        "You will need to insert a few agent functions here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwnMUsRIvkXj"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "\n",
        "n_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFqhB7p6SWpZ"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ03JCDFvkXj"
      },
      "outputs": [],
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"\n",
        "    This function should\n",
        "    - run a full game, actions given by agent's e-greedy policy\n",
        "    - train agent using agent.update(...) whenever it is possible\n",
        "    - return total reward\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s, _ = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s.\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, terminated, truncated, _ = env.step(a)\n",
        "\n",
        "        # train (update) agent for state s\n",
        "        <YOUR CODE>\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if terminated or truncated:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCi3HGNuvkXj"
      },
      "outputs": [],
      "source": [
        "agent = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI_cz8SsvkXk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "    agent.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.title(f\"eps = {agent.epsilon:.1e}, mean reward = {np.mean(rewards[-10:]):.1f}\")\n",
        "        plt.plot(rewards)\n",
        "        plt.grid()\n",
        "        plt.xlabel(\"n_iterations\")\n",
        "        plt.ylabel(\"total_reward\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9s6VltzULHe"
      },
      "source": [
        "# SARSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fRTjemzfp2_"
      },
      "outputs": [],
      "source": [
        "class SarsaAgent(QLearningAgent):\n",
        "    \"\"\"\n",
        "    An agent that changes some of q-learning functions to implement SARSA.\n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = Q(s, mu(a | s))\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if not possible_actions:\n",
        "            return 0.0\n",
        "\n",
        "        policy = []\n",
        "\n",
        "        state_value = <YOUR CODE: see docstring>\n",
        "\n",
        "        return state_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = SarsaAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "    agent.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.title(f\"eps = {agent.epsilon:.1e}, mean reward = {np.mean(rewards[-10:]):.1f}\")\n",
        "        plt.plot(rewards)\n",
        "        plt.grid()\n",
        "        plt.xlabel(\"n_iterations\")\n",
        "        plt.ylabel(\"total_reward\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ClifWalking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGPkx8rxiJWQ"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CliffWalking-v0', render_mode=\"rgb_array\")\n",
        "n_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDF1YOB_5cPr"
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.Series(x).ewm(span=span).mean().values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOb01LPU5j6I"
      },
      "outputs": [],
      "source": [
        "agent_sarsa = SarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('SARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zj1fJhg5_iz"
      },
      "outputs": [],
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env.unwrapped._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQSaqIED6i1E"
      },
      "outputs": [],
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaZ9BjGppYGd"
      },
      "source": [
        "### Decreasing É›"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ4GHuoBpVWT"
      },
      "outputs": [],
      "source": [
        "agent_sarsa = SarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        agent_ql.epsilon *= 0.9\n",
        "        clear_output(True)\n",
        "        print('SARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_evsarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_sarsa), label='sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xui5RHXMpqwc"
      },
      "outputs": [],
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqV9sbv6vkXl"
      },
      "source": [
        "# Discretised state spaces\n",
        "\n",
        "Use agent to train efficiently on `CartPole-v1`. This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
        "\n",
        "The simplest way is to use `round(x, n_digits)` (or `np.round`) to round a real number to a given amount of digits. The tricky part is to get the `n_digits` right for each state to train effectively.\n",
        "\n",
        "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz4p-nvRvkXl"
      },
      "outputs": [],
      "source": [
        "def make_env():\n",
        "    return gym.make(\"CartPole-v1\", render_mode=\"rgb_array\").env  # .env unwraps the TimeLimit wrapper\n",
        "\n",
        "env = make_env()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "s, _ = env.reset()\n",
        "print(f\"first state: {s}\")\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMK5_IhTvkXl"
      },
      "source": [
        "### Play a few games\n",
        "\n",
        "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iakjBaYvkXl"
      },
      "outputs": [],
      "source": [
        "def visualize_cartpole_observation_distribution(seen_observations):\n",
        "    seen_observations = np.array(seen_observations)\n",
        "\n",
        "    # The meaning of the observations is documented in\n",
        "    # https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(8, 6), sharey=True)\n",
        "    for i, title in enumerate(['Cart Position', 'Cart Velocity', 'Pole Angle', 'Pole Velocity At Tip']):\n",
        "        ax = axes[i // 2, i % 2]\n",
        "        ax.hist(seen_observations[:, i], bins=20)\n",
        "        ax.set_title(title)\n",
        "        xmin, xmax = ax.get_xlim()\n",
        "        ax.set_xlim(min(xmin, -xmax), max(-xmin, xmax))\n",
        "        ax.grid()\n",
        "    fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq8b6WlrvkXl"
      },
      "outputs": [],
      "source": [
        "seen_observations = []\n",
        "for _ in range(1000):\n",
        "    seen_observations.append(env.reset()[0])\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, terminated, truncated, _ = env.step(env.action_space.sample())\n",
        "        done = terminated or truncated\n",
        "        seen_observations.append(s)\n",
        "\n",
        "visualize_cartpole_observation_distribution(seen_observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jq_VvvSuLx3"
      },
      "outputs": [],
      "source": [
        "env.observation_space.low"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugvt5_fz2y1K"
      },
      "outputs": [],
      "source": [
        "env.observation_space.high"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6yKk9Hv_ZqS"
      },
      "outputs": [],
      "source": [
        "observation_dim = env.observation_space.shape[0]\n",
        "\n",
        "bins = (10, 10, 10, 10)\n",
        "observation_distributions = np.array(seen_observations)\n",
        "low = observation_distributions.min(axis=0)\n",
        "high = observation_distributions.max(axis=0)\n",
        "observation_bins = <YOUR CODE>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SomFeZS7vkXm"
      },
      "source": [
        "## Discretise environment's observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KMXAU0bvkXm"
      },
      "outputs": [],
      "source": [
        "class Discretiser(gym.ObservationWrapper):\n",
        "    def observation(self, state):\n",
        "        # Hint: use np.digitize and observation_bins or just round(x, n_digits)\n",
        "        obs = <YOUR CODE>\n",
        "        return tuple(obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFPrqyfavkXm"
      },
      "outputs": [],
      "source": [
        "env = Discretiser(make_env())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LLpQ5TPvkXm"
      },
      "outputs": [],
      "source": [
        "seen_observations = []\n",
        "for _ in range(1000):\n",
        "    seen_observations.append(env.reset()[0])\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, terminated, truncated, _ = env.step(env.action_space.sample())\n",
        "        seen_observations.append(s)\n",
        "        done = terminated or truncated\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "visualize_cartpole_observation_distribution(seen_observations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktKyq3g2vkXm"
      },
      "source": [
        "## Learn discretised policy\n",
        "\n",
        "Now let's train a policy that uses binarized state space.\n",
        "\n",
        "__Tips:__\n",
        "\n",
        "* Note that increasing the number of digits for one dimension of the observations increases your state space by a factor of $10$.\n",
        "* If your binarization is too fine-grained, your agent will take much longer than 10000 steps to converge. You can either increase the number of iterations and reduce epsilon decay or change binarization. In practice we found that this kind of mistake is rather frequent.\n",
        "* If your discretisation is too coarse, your agent may fail to find the optimal policy. In practice we found that on this particular environment this kind of mistake is rare.\n",
        "* **Start with a coarse discretisation** and make it more fine-grained if that seems necessary.\n",
        "* Having $10^3$â€“$10^4$ distinct states is recommended (`len(agent._qvalues)`), but not required.\n",
        "* If things don't work without annealing $\\varepsilon$, consider adding that, but make sure that it doesn't go to zero too quickly.\n",
        "\n",
        "A reasonable agent should attain an average reward of at least 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwyPLDO4vkXm"
      },
      "outputs": [],
      "source": [
        "agent = QLearningAgent(\n",
        "    alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "    get_legal_actions=lambda s: range(n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOpXAY_ZvkXm"
      },
      "outputs": [],
      "source": [
        "rewards = []\n",
        "epsilons = []\n",
        "\n",
        "for i in range(10000):\n",
        "    reward = play_and_train(env, agent)\n",
        "    rewards.append(reward)\n",
        "    epsilons.append(agent.epsilon)\n",
        "\n",
        "    # OPTIONAL: <YOUR CODE: adjust epsilon>\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        agent.epsilon *= 0.99\n",
        "        rewards_ewma = moving_average(rewards)\n",
        "\n",
        "        clear_output(True)\n",
        "        plt.plot(rewards, label='rewards')\n",
        "        plt.plot(rewards_ewma, label='rewards ewma@100')\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.xlabel(\"n_iterations\")\n",
        "        plt.ylabel(\"total_reward\")\n",
        "        plt.title(f\"eps = {agent.epsilon}, rewards ewma@100 = {rewards_ewma[-1]:.1f}\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtGz0_l0vkXn"
      },
      "outputs": [],
      "source": [
        "print(f\"Your agent has learned {len(agent._qvalues)} Q-values.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
